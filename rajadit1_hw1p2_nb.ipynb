{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02e87890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "from nltk.corpus import movie_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1e54254",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviedir = r'C:\\Users\\aditt\\AppData\\Roaming\\nltk_data\\corpora\\movie_reviews'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1dff815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_train = load_files(moviedir, shuffle=True)\n",
    "len(movie_train.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7595c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target names (\"classes\") are automatically generated from subfolder names\n",
    "movie_train.target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15547151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \\nonce again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \\nin this so cal\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_train.data[0][:500]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed634c0b",
   "metadata": {},
   "source": [
    "### Detour for Countvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b224cd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Turn off pretty printing of jupyter notebook... it generates long lines\n",
    "%pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da440ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = ['A rose is a rose is a rose is a rose.',\n",
    "         'Oh, what a fine day it is.',\n",
    "        \"It ain't over till it's over, I tell you!!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d1ed998",
   "metadata": {},
   "outputs": [],
   "source": [
    "foovec = CountVectorizer(min_df=1, tokenizer=nltk.word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94513e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 4,\n",
       " 'rose': 14,\n",
       " 'is': 9,\n",
       " '.': 3,\n",
       " 'oh': 12,\n",
       " ',': 2,\n",
       " 'what': 17,\n",
       " 'fine': 7,\n",
       " 'day': 6,\n",
       " 'it': 10,\n",
       " 'ai': 5,\n",
       " \"n't\": 11,\n",
       " 'over': 13,\n",
       " 'till': 16,\n",
       " \"'s\": 1,\n",
       " 'i': 8,\n",
       " 'tell': 15,\n",
       " 'you': 18,\n",
       " '!': 0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sents turned into sparse vector of word frequency counts\n",
    "sents_counts = foovec.fit_transform(sents)\n",
    "# foovec now contains vocab dictionary which maps unique words to indexes\n",
    "foovec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1242ba89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 19)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sents_counts has a dimension of 3 (document count) by 19 (# of unique words)\n",
    "sents_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e62a81dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 4, 0, 0, 0, 0, 3, 0, 0, 0, 0, 4, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [2, 1, 1, 0, 0, 1, 0, 0, 1, 0, 2, 1, 0, 2, 0, 1, 1, 0, 1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_counts.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "084ed86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw frequency counts into TF-IDF (Term Frequency -- Inverse Document Frequency) values\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "sents_tfidf = tfidf_transformer.fit_transform(sents_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c70eb826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.13650997, 0.54603988,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.40952991,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.71797683,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.28969526, 0.28969526, 0.28969526,\n",
       "        0.        , 0.38091445, 0.38091445, 0.        , 0.28969526,\n",
       "        0.28969526, 0.        , 0.38091445, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.38091445, 0.        ],\n",
       "       [0.47282517, 0.23641258, 0.17979786, 0.        , 0.        ,\n",
       "        0.23641258, 0.        , 0.        , 0.23641258, 0.        ,\n",
       "        0.35959573, 0.23641258, 0.        , 0.47282517, 0.        ,\n",
       "        0.23641258, 0.23641258, 0.        , 0.23641258]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF values\n",
    "# raw counts have been normalized against document length, \n",
    "# terms that are found across many docs are weighted down\n",
    "sents_tfidf.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e5a7432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize movie_vector object, and then turn movie train data into a vector \n",
    "movie_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize)         # use all 25K words. 82.2% acc.\n",
    "# movie_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize, max_features = 3000) # use top 3000 words only. 78.5% acc.\n",
    "movie_counts = movie_vec.fit_transform(movie_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05b00212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19604"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_vec.vocabulary_.get('screen')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9791eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 25280)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_counts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e67078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "movie_tfidf = tfidf_transformer.fit_transform(movie_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21462a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 25280)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7618019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Split data into training and test sets\n",
    "# from sklearn.cross_validation import train_test_split  # deprecated in 0.18\n",
    "from sklearn.model_selection import train_test_split\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    movie_tfidf, movie_train.target, test_size = 0.20, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2b9111e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Multimoda Naive Bayes classifier\n",
    "clf = MultinomialNB().fit(docs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30d18180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n",
      "Precision: 0.8315217391304348\n",
      "Recall: 0.788659793814433\n",
      "F1: 0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results, find accuracy\n",
    "y_pred = clf.predict(docs_test)\n",
    "print('Accuracy: {}'.format(sklearn.metrics.accuracy_score(y_test, y_pred)))\n",
    "print('Precision: {}'.format(sklearn.metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: {}'.format(sklearn.metrics.recall_score(y_test, y_pred)))\n",
    "print('F1: {}'.format(sklearn.metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "78c0081a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[175,  31],\n",
       "       [ 41, 153]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4caf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46acfdda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856fd9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
